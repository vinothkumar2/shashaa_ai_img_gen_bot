{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrZilheiM6lC",
        "outputId": "fe0e6406-08ad-47e6-b76f-84edff28065f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 13 16:00:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrEOZtWwMwWS",
        "outputId": "bc4784e1-b38e-4dbc-f051-c89f99bb8ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'shashaa_ai_img_gen_bot'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), 3.14 KiB | 3.14 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vinothkumar2/shashaa_ai_img_gen_bot.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vzMZXnnNEQb",
        "outputId": "4c9175fa-e5be-4e2a-c96b-a03eae71a9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi7Z09u-NHQI",
        "outputId": "50dace1d-1919-4e74-a2b5-687eb89551de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting diffusers==0.7.2\n",
            "  Downloading diffusers-0.7.2-py3-none-any.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.24.0\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.8/39.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.1.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-telegram-bot>=20.0a2\n",
            "  Downloading python_telegram_bot-20.2-py3-none-any.whl (535 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.8/535.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.20.0\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting huggingface_hub==0.10.1\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (3.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: Pillow<10.0 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers==0.7.2->-r requirements.txt (line 1)) (6.2.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0->-r requirements.txt (line 2)) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0->-r requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.24.0->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 4)) (0.2.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub==0.10.1->-r requirements.txt (line 7)) (4.5.0)\n",
            "Collecting httpx~=0.23.3\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx~=0.23.3->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx~=0.23.3->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata->diffusers==0.7.2->-r requirements.txt (line 1)) (3.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.7.2->-r requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.7.2->-r requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.7.2->-r requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.3->python-telegram-bot>=20.0a2->-r requirements.txt (line 5)) (3.6.2)\n",
            "Collecting h11<0.15,>=0.13\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, rfc3986, scipy, python-dotenv, h11, ftfy, huggingface_hub, httpcore, transformers, httpx, diffusers, python-telegram-bot\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diffusers-0.7.2 ftfy-6.1.1 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 huggingface_hub-0.10.1 python-dotenv-1.0.0 python-telegram-bot-20.2 rfc3986-1.5.0 scipy-1.7.3 tokenizers-0.13.3 transformers-4.24.0\n"
          ]
        }
      ],
      "source": [
        "!cd shashaa_ai_img_gen_bot && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "683563d8ccd84ee795a84368e1327525",
            "65a5af07183c49679414297bfab97ac1",
            "0d3f2e59b7d3455fb6ab687edf68894a",
            "c05b54a5a519461680346b97613cf569",
            "0f6d549239884d4790f7504add08aa5d",
            "5b939aac19b5469ea5ed3668a92617f0",
            "7fa67d9e650e422e8c504fdd1999508f",
            "41ef71803dc249a2b0101121a5a24693",
            "bee3ce59c52743cbada04a256d5431a8",
            "0588e46ff66147f193f5caec09535bea",
            "fbba3347837a4ddb988ac65e2ae2bcac",
            "07bf9e3f7e3d4fe6bdb4c7f5b20bf67f",
            "e281cc9bb5d94ef7b66196c06f110f2e",
            "ec24325570aa4e7e9a7f40c894a01007"
          ]
        },
        "id": "YCXFpbnDNdR8",
        "outputId": "1ff0a359-0ce4-4f86-9176-1ee6d2e29c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jRa4qm7cPNNj"
      },
      "outputs": [],
      "source": [
        "TG_TOKEN = '5658211267:AAF6ZqtKcva0oQPAgp1pGn7YwrAv5O1jkx8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yXblRtBjNh65"
      },
      "outputs": [],
      "source": [
        "!printf \"TG_TOKEN='{TG_TOKEN}'\\nSAFETY_CHECKER='false'\" > shashaa_ai_img_gen_bot/.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27monR3JOYtz",
        "outputId": "c54a4d70-519b-4ce5-8e6e-3d4603b7950e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TG_TOKEN='5658211267:AAF6ZqtKcva0oQPAgp1pGn7YwrAv5O1jkx8'\n",
            "SAFETY_CHECKER='false'"
          ]
        }
      ],
      "source": [
        "!cat shashaa_ai_img_gen_bot/.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZSvSocMOvc1",
        "outputId": "f86e76a3-cf20-42e5-c6e3-6222dc9c9745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-13 16:02:22.659092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "Downloading: 100% 543/543 [00:00<00:00, 394kB/s]\n",
            "Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n",
            "Downloading: 100% 342/342 [00:00<00:00, 330kB/s]\n",
            "Fetching 15 files:   7% 1/15 [00:00<00:06,  2.03it/s]\n",
            "Downloading: 100% 4.70k/4.70k [00:00<00:00, 3.93MB/s]\n",
            "Fetching 15 files:  20% 3/15 [00:00<00:03,  3.21it/s]\n",
            "Downloading:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   2% 10.6M/608M [00:00<00:05, 106MB/s]\u001b[A\n",
            "Downloading:   4% 21.6M/608M [00:00<00:05, 108MB/s]\u001b[A\n",
            "Downloading:   5% 32.5M/608M [00:00<00:05, 106MB/s]\u001b[A\n",
            "Downloading:   7% 43.4M/608M [00:00<00:05, 108MB/s]\u001b[A\n",
            "Downloading:   9% 54.5M/608M [00:00<00:05, 109MB/s]\u001b[A\n",
            "Downloading:  11% 65.7M/608M [00:00<00:04, 110MB/s]\u001b[A\n",
            "Downloading:  13% 76.7M/608M [00:00<00:04, 109MB/s]\u001b[A\n",
            "Downloading:  14% 87.5M/608M [00:00<00:04, 107MB/s]\u001b[A\n",
            "Downloading:  16% 98.2M/608M [00:00<00:04, 106MB/s]\u001b[A\n",
            "Downloading:  18% 109M/608M [00:01<00:04, 107MB/s] \u001b[A\n",
            "Downloading:  20% 120M/608M [00:01<00:04, 102MB/s]\u001b[A\n",
            "Downloading:  21% 130M/608M [00:01<00:04, 103MB/s]\u001b[A\n",
            "Downloading:  23% 141M/608M [00:01<00:04, 105MB/s]\u001b[A\n",
            "Downloading:  25% 152M/608M [00:01<00:04, 97.0MB/s]\u001b[A\n",
            "Downloading:  27% 162M/608M [00:01<00:04, 95.6MB/s]\u001b[A\n",
            "Downloading:  28% 173M/608M [00:01<00:04, 98.9MB/s]\u001b[A\n",
            "Downloading:  30% 183M/608M [00:01<00:04, 99.2MB/s]\u001b[A\n",
            "Downloading:  32% 193M/608M [00:01<00:04, 88.4MB/s]\u001b[A\n",
            "Downloading:  33% 203M/608M [00:02<00:04, 91.8MB/s]\u001b[A\n",
            "Downloading:  35% 213M/608M [00:02<00:04, 94.6MB/s]\u001b[A\n",
            "Downloading:  37% 223M/608M [00:02<00:03, 96.7MB/s]\u001b[A\n",
            "Downloading:  38% 233M/608M [00:02<00:03, 98.6MB/s]\u001b[A\n",
            "Downloading:  40% 244M/608M [00:02<00:03, 99.6MB/s]\u001b[A\n",
            "Downloading:  42% 254M/608M [00:02<00:03, 101MB/s] \u001b[A\n",
            "Downloading:  43% 264M/608M [00:02<00:03, 101MB/s]\u001b[A\n",
            "Downloading:  45% 275M/608M [00:02<00:03, 103MB/s]\u001b[A\n",
            "Downloading:  47% 286M/608M [00:02<00:03, 104MB/s]\u001b[A\n",
            "Downloading:  49% 296M/608M [00:02<00:03, 102MB/s]\u001b[A\n",
            "Downloading:  50% 306M/608M [00:03<00:03, 91.6MB/s]\u001b[A\n",
            "Downloading:  52% 317M/608M [00:03<00:03, 94.7MB/s]\u001b[A\n",
            "Downloading:  54% 327M/608M [00:03<00:02, 97.5MB/s]\u001b[A\n",
            "Downloading:  55% 337M/608M [00:03<00:02, 94.0MB/s]\u001b[A\n",
            "Downloading:  57% 347M/608M [00:03<00:02, 95.6MB/s]\u001b[A\n",
            "Downloading:  59% 357M/608M [00:03<00:02, 98.0MB/s]\u001b[A\n",
            "Downloading:  60% 368M/608M [00:03<00:02, 98.8MB/s]\u001b[A\n",
            "Downloading:  62% 378M/608M [00:03<00:02, 93.9MB/s]\u001b[A\n",
            "Downloading:  64% 387M/608M [00:03<00:02, 94.8MB/s]\u001b[A\n",
            "Downloading:  65% 398M/608M [00:03<00:02, 97.5MB/s]\u001b[A\n",
            "Downloading:  67% 408M/608M [00:04<00:02, 97.2MB/s]\u001b[A\n",
            "Downloading:  69% 418M/608M [00:04<00:01, 99.3MB/s]\u001b[A\n",
            "Downloading:  70% 428M/608M [00:04<00:01, 101MB/s] \u001b[A\n",
            "Downloading:  72% 439M/608M [00:04<00:01, 97.3MB/s]\u001b[A\n",
            "Downloading:  74% 448M/608M [00:04<00:01, 89.3MB/s]\u001b[A\n",
            "Downloading:  75% 459M/608M [00:04<00:01, 93.9MB/s]\u001b[A\n",
            "Downloading:  77% 469M/608M [00:04<00:01, 95.7MB/s]\u001b[A\n",
            "Downloading:  79% 480M/608M [00:04<00:01, 99.9MB/s]\u001b[A\n",
            "Downloading:  81% 490M/608M [00:04<00:01, 99.6MB/s]\u001b[A\n",
            "Downloading:  82% 501M/608M [00:05<00:01, 102MB/s] \u001b[A\n",
            "Downloading:  84% 512M/608M [00:05<00:00, 104MB/s]\u001b[A\n",
            "Downloading:  86% 522M/608M [00:05<00:00, 98.8MB/s]\u001b[A\n",
            "Downloading:  88% 533M/608M [00:05<00:00, 102MB/s] \u001b[A\n",
            "Downloading:  89% 544M/608M [00:05<00:00, 105MB/s]\u001b[A\n",
            "Downloading:  91% 555M/608M [00:05<00:00, 98.1MB/s]\u001b[A\n",
            "Downloading:  93% 566M/608M [00:05<00:00, 103MB/s] \u001b[A\n",
            "Downloading:  95% 577M/608M [00:05<00:00, 106MB/s]\u001b[A\n",
            "Downloading:  97% 588M/608M [00:05<00:00, 91.9MB/s]\u001b[A\n",
            "Downloading: 100% 608M/608M [00:06<00:00, 99.4MB/s]\n",
            "Fetching 15 files:  27% 4/15 [00:07<00:26,  2.41s/it]\n",
            "Downloading: 100% 307/307 [00:00<00:00, 301kB/s]\n",
            "Fetching 15 files:  33% 5/15 [00:07<00:17,  1.77s/it]\n",
            "Downloading: 100% 636/636 [00:00<00:00, 622kB/s]\n",
            "Fetching 15 files:  40% 6/15 [00:08<00:12,  1.36s/it]\n",
            "Downloading:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   4% 9.65M/246M [00:00<00:02, 96.4MB/s]\u001b[A\n",
            "Downloading:   8% 20.3M/246M [00:00<00:02, 102MB/s] \u001b[A\n",
            "Downloading:  13% 31.0M/246M [00:00<00:02, 104MB/s]\u001b[A\n",
            "Downloading:  17% 41.4M/246M [00:00<00:02, 92.9MB/s]\u001b[A\n",
            "Downloading:  21% 50.9M/246M [00:00<00:02, 93.6MB/s]\u001b[A\n",
            "Downloading:  25% 60.3M/246M [00:00<00:02, 91.1MB/s]\u001b[A\n",
            "Downloading:  29% 70.3M/246M [00:00<00:01, 93.8MB/s]\u001b[A\n",
            "Downloading:  33% 80.6M/246M [00:00<00:01, 96.4MB/s]\u001b[A\n",
            "Downloading:  37% 90.3M/246M [00:00<00:01, 96.2MB/s]\u001b[A\n",
            "Downloading:  41% 100M/246M [00:01<00:01, 97.8MB/s] \u001b[A\n",
            "Downloading:  45% 110M/246M [00:01<00:01, 98.4MB/s]\u001b[A\n",
            "Downloading:  49% 120M/246M [00:01<00:01, 88.6MB/s]\u001b[A\n",
            "Downloading:  53% 130M/246M [00:01<00:01, 91.4MB/s]\u001b[A\n",
            "Downloading:  57% 139M/246M [00:01<00:01, 90.4MB/s]\u001b[A\n",
            "Downloading:  61% 149M/246M [00:01<00:01, 92.9MB/s]\u001b[A\n",
            "Downloading:  64% 159M/246M [00:01<00:01, 84.5MB/s]\u001b[A\n",
            "Downloading:  68% 167M/246M [00:01<00:00, 84.9MB/s]\u001b[A\n",
            "Downloading:  72% 176M/246M [00:01<00:00, 86.3MB/s]\u001b[A\n",
            "Downloading:  76% 186M/246M [00:02<00:00, 90.4MB/s]\u001b[A\n",
            "Downloading:  80% 196M/246M [00:02<00:00, 92.9MB/s]\u001b[A\n",
            "Downloading:  84% 206M/246M [00:02<00:00, 94.4MB/s]\u001b[A\n",
            "Downloading:  88% 216M/246M [00:02<00:00, 95.0MB/s]\u001b[A\n",
            "Downloading:  92% 225M/246M [00:02<00:00, 86.8MB/s]\u001b[A\n",
            "Downloading:  95% 234M/246M [00:02<00:00, 88.0MB/s]\u001b[A\n",
            "Downloading: 100% 246M/246M [00:02<00:00, 90.0MB/s]\n",
            "Fetching 15 files:  47% 7/15 [00:11<00:15,  1.88s/it]\n",
            "Downloading: 100% 525k/525k [00:00<00:00, 43.1MB/s]\n",
            "Fetching 15 files:  53% 8/15 [00:11<00:10,  1.46s/it]\n",
            "Downloading: 100% 472/472 [00:00<00:00, 266kB/s]\n",
            "Fetching 15 files:  60% 9/15 [00:12<00:06,  1.16s/it]\n",
            "Downloading: 100% 822/822 [00:00<00:00, 494kB/s]\n",
            "Fetching 15 files:  67% 10/15 [00:12<00:04,  1.04it/s]\n",
            "Downloading:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading: 100% 1.06M/1.06M [00:00<00:00, 5.00MB/s]\n",
            "Fetching 15 files:  73% 11/15 [00:13<00:03,  1.11it/s]\n",
            "Downloading: 100% 806/806 [00:00<00:00, 716kB/s]\n",
            "Fetching 15 files:  80% 12/15 [00:14<00:02,  1.29it/s]\n",
            "Downloading:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   0% 7.95M/1.72G [00:00<00:21, 79.5MB/s]\u001b[A\n",
            "Downloading:   1% 15.9M/1.72G [00:00<00:22, 76.1MB/s]\u001b[A\n",
            "Downloading:   1% 23.5M/1.72G [00:00<00:24, 69.5MB/s]\u001b[A\n",
            "Downloading:   2% 33.2M/1.72G [00:00<00:21, 79.6MB/s]\u001b[A\n",
            "Downloading:   2% 41.3M/1.72G [00:00<00:21, 79.9MB/s]\u001b[A\n",
            "Downloading:   3% 49.3M/1.72G [00:00<00:21, 78.1MB/s]\u001b[A\n",
            "Downloading:   3% 57.3M/1.72G [00:00<00:21, 78.6MB/s]\u001b[A\n",
            "Downloading:   4% 65.3M/1.72G [00:00<00:20, 78.8MB/s]\u001b[A\n",
            "Downloading:   4% 73.2M/1.72G [00:00<00:20, 78.7MB/s]\u001b[A\n",
            "Downloading:   5% 81.2M/1.72G [00:01<00:20, 79.3MB/s]\u001b[A\n",
            "Downloading:   5% 89.2M/1.72G [00:01<00:20, 78.3MB/s]\u001b[A\n",
            "Downloading:   6% 97.2M/1.72G [00:01<00:20, 78.9MB/s]\u001b[A\n",
            "Downloading:   6% 105M/1.72G [00:01<00:20, 79.9MB/s] \u001b[A\n",
            "Downloading:   7% 113M/1.72G [00:01<00:20, 79.6MB/s]\u001b[A\n",
            "Downloading:   7% 121M/1.72G [00:01<00:21, 74.3MB/s]\u001b[A\n",
            "Downloading:   8% 131M/1.72G [00:01<00:19, 80.3MB/s]\u001b[A\n",
            "Downloading:   8% 139M/1.72G [00:01<00:21, 73.9MB/s]\u001b[A\n",
            "Downloading:   9% 147M/1.72G [00:01<00:21, 72.8MB/s]\u001b[A\n",
            "Downloading:   9% 154M/1.72G [00:02<00:22, 70.9MB/s]\u001b[A\n",
            "Downloading:   9% 162M/1.72G [00:02<00:20, 74.6MB/s]\u001b[A\n",
            "Downloading:  10% 170M/1.72G [00:02<00:20, 74.8MB/s]\u001b[A\n",
            "Downloading:  10% 177M/1.72G [00:02<00:21, 72.0MB/s]\u001b[A\n",
            "Downloading:  11% 185M/1.72G [00:02<00:20, 73.9MB/s]\u001b[A\n",
            "Downloading:  11% 193M/1.72G [00:02<00:20, 74.9MB/s]\u001b[A\n",
            "Downloading:  12% 201M/1.72G [00:02<00:19, 76.2MB/s]\u001b[A\n",
            "Downloading:  12% 209M/1.72G [00:02<00:19, 77.6MB/s]\u001b[A\n",
            "Downloading:  13% 217M/1.72G [00:02<00:19, 77.5MB/s]\u001b[A\n",
            "Downloading:  13% 225M/1.72G [00:02<00:20, 73.4MB/s]\u001b[A\n",
            "Downloading:  14% 233M/1.72G [00:03<00:19, 75.1MB/s]\u001b[A\n",
            "Downloading:  14% 240M/1.72G [00:03<00:19, 76.1MB/s]\u001b[A\n",
            "Downloading:  14% 249M/1.72G [00:03<00:18, 77.8MB/s]\u001b[A\n",
            "Downloading:  15% 256M/1.72G [00:03<00:19, 76.0MB/s]\u001b[A\n",
            "Downloading:  15% 264M/1.72G [00:03<00:19, 75.1MB/s]\u001b[A\n",
            "Downloading:  16% 272M/1.72G [00:03<00:18, 76.2MB/s]\u001b[A\n",
            "Downloading:  16% 280M/1.72G [00:03<00:19, 73.1MB/s]\u001b[A\n",
            "Downloading:  17% 287M/1.72G [00:03<00:19, 72.8MB/s]\u001b[A\n",
            "Downloading:  17% 295M/1.72G [00:03<00:18, 75.5MB/s]\u001b[A\n",
            "Downloading:  18% 303M/1.72G [00:03<00:18, 76.4MB/s]\u001b[A\n",
            "Downloading:  18% 311M/1.72G [00:04<00:18, 76.8MB/s]\u001b[A\n",
            "Downloading:  19% 319M/1.72G [00:04<00:18, 77.3MB/s]\u001b[A\n",
            "Downloading:  19% 327M/1.72G [00:04<00:17, 80.0MB/s]\u001b[A\n",
            "Downloading:  20% 335M/1.72G [00:04<00:17, 78.6MB/s]\u001b[A\n",
            "Downloading:  20% 343M/1.72G [00:04<00:18, 73.4MB/s]\u001b[A\n",
            "Downloading:  20% 351M/1.72G [00:04<00:18, 74.7MB/s]\u001b[A\n",
            "Downloading:  21% 359M/1.72G [00:04<00:18, 72.9MB/s]\u001b[A\n",
            "Downloading:  21% 366M/1.72G [00:04<00:18, 72.3MB/s]\u001b[A\n",
            "Downloading:  22% 374M/1.72G [00:04<00:17, 75.5MB/s]\u001b[A\n",
            "Downloading:  22% 382M/1.72G [00:05<00:17, 76.8MB/s]\u001b[A\n",
            "Downloading:  23% 390M/1.72G [00:05<00:17, 74.0MB/s]\u001b[A\n",
            "Downloading:  23% 400M/1.72G [00:05<00:16, 80.1MB/s]\u001b[A\n",
            "Downloading:  24% 409M/1.72G [00:05<00:15, 83.2MB/s]\u001b[A\n",
            "Downloading:  24% 418M/1.72G [00:05<00:15, 86.6MB/s]\u001b[A\n",
            "Downloading:  25% 427M/1.72G [00:05<00:16, 79.1MB/s]\u001b[A\n",
            "Downloading:  25% 436M/1.72G [00:05<00:15, 82.7MB/s]\u001b[A\n",
            "Downloading:  26% 446M/1.72G [00:05<00:14, 87.4MB/s]\u001b[A\n",
            "Downloading:  26% 456M/1.72G [00:05<00:14, 90.0MB/s]\u001b[A\n",
            "Downloading:  27% 465M/1.72G [00:05<00:13, 91.2MB/s]\u001b[A\n",
            "Downloading:  28% 474M/1.72G [00:06<00:13, 92.1MB/s]\u001b[A\n",
            "Downloading:  28% 484M/1.72G [00:06<00:13, 90.8MB/s]\u001b[A\n",
            "Downloading:  29% 493M/1.72G [00:06<00:13, 90.5MB/s]\u001b[A\n",
            "Downloading:  29% 502M/1.72G [00:06<00:13, 89.5MB/s]\u001b[A\n",
            "Downloading:  30% 511M/1.72G [00:06<00:14, 84.6MB/s]\u001b[A\n",
            "Downloading:  30% 520M/1.72G [00:06<00:13, 85.8MB/s]\u001b[A\n",
            "Downloading:  31% 529M/1.72G [00:06<00:13, 87.4MB/s]\u001b[A\n",
            "Downloading:  31% 538M/1.72G [00:06<00:14, 80.0MB/s]\u001b[A\n",
            "Downloading:  32% 547M/1.72G [00:06<00:13, 84.2MB/s]\u001b[A\n",
            "Downloading:  32% 557M/1.72G [00:07<00:13, 87.9MB/s]\u001b[A\n",
            "Downloading:  33% 566M/1.72G [00:07<00:13, 87.5MB/s]\u001b[A\n",
            "Downloading:  33% 575M/1.72G [00:07<00:14, 81.1MB/s]\u001b[A\n",
            "Downloading:  34% 583M/1.72G [00:07<00:13, 81.8MB/s]\u001b[A\n",
            "Downloading:  34% 591M/1.72G [00:07<00:14, 79.6MB/s]\u001b[A\n",
            "Downloading:  35% 600M/1.72G [00:07<00:13, 82.1MB/s]\u001b[A\n",
            "Downloading:  35% 608M/1.72G [00:07<00:13, 81.1MB/s]\u001b[A\n",
            "Downloading:  36% 617M/1.72G [00:07<00:13, 81.9MB/s]\u001b[A\n",
            "Downloading:  36% 625M/1.72G [00:07<00:13, 82.5MB/s]\u001b[A\n",
            "Downloading:  37% 634M/1.72G [00:07<00:12, 85.0MB/s]\u001b[A\n",
            "Downloading:  37% 643M/1.72G [00:08<00:13, 81.7MB/s]\u001b[A\n",
            "Downloading:  38% 652M/1.72G [00:08<00:12, 83.3MB/s]\u001b[A\n",
            "Downloading:  38% 661M/1.72G [00:08<00:12, 87.5MB/s]\u001b[A\n",
            "Downloading:  39% 670M/1.72G [00:08<00:12, 84.5MB/s]\u001b[A\n",
            "Downloading:  40% 680M/1.72G [00:08<00:11, 88.4MB/s]\u001b[A\n",
            "Downloading:  40% 690M/1.72G [00:08<00:11, 91.9MB/s]\u001b[A\n",
            "Downloading:  41% 699M/1.72G [00:08<00:11, 92.5MB/s]\u001b[A\n",
            "Downloading:  41% 709M/1.72G [00:08<00:11, 88.1MB/s]\u001b[A\n",
            "Downloading:  42% 718M/1.72G [00:08<00:11, 90.4MB/s]\u001b[A\n",
            "Downloading:  42% 728M/1.72G [00:09<00:10, 91.4MB/s]\u001b[A\n",
            "Downloading:  43% 737M/1.72G [00:09<00:12, 81.0MB/s]\u001b[A\n",
            "Downloading:  43% 746M/1.72G [00:09<00:11, 85.2MB/s]\u001b[A\n",
            "Downloading:  44% 755M/1.72G [00:09<00:11, 86.0MB/s]\u001b[A\n",
            "Downloading:  44% 764M/1.72G [00:09<00:11, 82.2MB/s]\u001b[A\n",
            "Downloading:  45% 772M/1.72G [00:09<00:11, 79.3MB/s]\u001b[A\n",
            "Downloading:  45% 782M/1.72G [00:09<00:11, 83.7MB/s]\u001b[A\n",
            "Downloading:  46% 790M/1.72G [00:09<00:11, 78.4MB/s]\u001b[A\n",
            "Downloading:  46% 798M/1.72G [00:09<00:12, 75.5MB/s]\u001b[A\n",
            "Downloading:  47% 806M/1.72G [00:10<00:13, 66.7MB/s]\u001b[A\n",
            "Downloading:  47% 813M/1.72G [00:10<00:13, 65.4MB/s]\u001b[A\n",
            "Downloading:  48% 820M/1.72G [00:10<00:13, 65.6MB/s]\u001b[A\n",
            "Downloading:  48% 826M/1.72G [00:10<00:13, 65.9MB/s]\u001b[A\n",
            "Downloading:  48% 833M/1.72G [00:10<00:13, 66.2MB/s]\u001b[A\n",
            "Downloading:  49% 840M/1.72G [00:10<00:13, 64.8MB/s]\u001b[A\n",
            "Downloading:  49% 846M/1.72G [00:10<00:13, 65.5MB/s]\u001b[A\n",
            "Downloading:  50% 853M/1.72G [00:10<00:13, 65.7MB/s]\u001b[A\n",
            "Downloading:  50% 860M/1.72G [00:10<00:13, 63.7MB/s]\u001b[A\n",
            "Downloading:  50% 866M/1.72G [00:11<00:13, 62.4MB/s]\u001b[A\n",
            "Downloading:  51% 872M/1.72G [00:11<00:13, 62.2MB/s]\u001b[A\n",
            "Downloading:  51% 878M/1.72G [00:11<00:13, 61.8MB/s]\u001b[A\n",
            "Downloading:  51% 885M/1.72G [00:11<00:14, 59.3MB/s]\u001b[A\n",
            "Downloading:  52% 891M/1.72G [00:11<00:13, 60.5MB/s]\u001b[A\n",
            "Downloading:  52% 897M/1.72G [00:11<00:13, 60.3MB/s]\u001b[A\n",
            "Downloading:  53% 903M/1.72G [00:11<00:14, 55.5MB/s]\u001b[A\n",
            "Downloading:  53% 909M/1.72G [00:11<00:16, 49.6MB/s]\u001b[A\n",
            "Downloading:  53% 915M/1.72G [00:11<00:15, 52.5MB/s]\u001b[A\n",
            "Downloading:  54% 921M/1.72G [00:12<00:14, 54.2MB/s]\u001b[A\n",
            "Downloading:  54% 927M/1.72G [00:12<00:14, 56.0MB/s]\u001b[A\n",
            "Downloading:  54% 933M/1.72G [00:12<00:13, 57.6MB/s]\u001b[A\n",
            "Downloading:  55% 939M/1.72G [00:12<00:13, 57.9MB/s]\u001b[A\n",
            "Downloading:  55% 945M/1.72G [00:12<00:13, 59.1MB/s]\u001b[A\n",
            "Downloading:  55% 951M/1.72G [00:12<00:12, 59.4MB/s]\u001b[A\n",
            "Downloading:  56% 957M/1.72G [00:12<00:13, 57.4MB/s]\u001b[A\n",
            "Downloading:  56% 963M/1.72G [00:12<00:13, 56.1MB/s]\u001b[A\n",
            "Downloading:  56% 968M/1.72G [00:12<00:13, 55.5MB/s]\u001b[A\n",
            "Downloading:  57% 974M/1.72G [00:12<00:13, 56.7MB/s]\u001b[A\n",
            "Downloading:  57% 981M/1.72G [00:13<00:12, 58.3MB/s]\u001b[A\n",
            "Downloading:  57% 987M/1.72G [00:13<00:12, 59.1MB/s]\u001b[A\n",
            "Downloading:  58% 993M/1.72G [00:13<00:12, 59.6MB/s]\u001b[A\n",
            "Downloading:  58% 999M/1.72G [00:13<00:12, 59.3MB/s]\u001b[A\n",
            "Downloading:  58% 1.00G/1.72G [00:13<00:11, 59.8MB/s]\u001b[A\n",
            "Downloading:  59% 1.01G/1.72G [00:13<00:11, 60.8MB/s]\u001b[A\n",
            "Downloading:  59% 1.02G/1.72G [00:13<00:11, 62.0MB/s]\u001b[A\n",
            "Downloading:  60% 1.02G/1.72G [00:13<00:11, 59.3MB/s]\u001b[A\n",
            "Downloading:  60% 1.03G/1.72G [00:13<00:11, 58.7MB/s]\u001b[A\n",
            "Downloading:  60% 1.04G/1.72G [00:13<00:11, 59.2MB/s]\u001b[A\n",
            "Downloading:  61% 1.04G/1.72G [00:14<00:11, 59.9MB/s]\u001b[A\n",
            "Downloading:  61% 1.05G/1.72G [00:14<00:11, 60.1MB/s]\u001b[A\n",
            "Downloading:  61% 1.06G/1.72G [00:14<00:10, 64.8MB/s]\u001b[A\n",
            "Downloading:  62% 1.06G/1.72G [00:14<00:09, 70.3MB/s]\u001b[A\n",
            "Downloading:  63% 1.07G/1.72G [00:14<00:07, 81.8MB/s]\u001b[A\n",
            "Downloading:  63% 1.09G/1.72G [00:14<00:07, 89.7MB/s]\u001b[A\n",
            "Downloading:  64% 1.09G/1.72G [00:14<00:07, 86.5MB/s]\u001b[A\n",
            "Downloading:  64% 1.10G/1.72G [00:14<00:06, 89.8MB/s]\u001b[A\n",
            "Downloading:  65% 1.11G/1.72G [00:14<00:07, 86.2MB/s]\u001b[A\n",
            "Downloading:  65% 1.12G/1.72G [00:15<00:07, 83.5MB/s]\u001b[A\n",
            "Downloading:  66% 1.13G/1.72G [00:15<00:07, 83.1MB/s]\u001b[A\n",
            "Downloading:  66% 1.14G/1.72G [00:15<00:06, 85.7MB/s]\u001b[A\n",
            "Downloading:  67% 1.15G/1.72G [00:15<00:06, 84.5MB/s]\u001b[A\n",
            "Downloading:  67% 1.16G/1.72G [00:15<00:07, 79.9MB/s]\u001b[A\n",
            "Downloading:  68% 1.17G/1.72G [00:15<00:06, 81.9MB/s]\u001b[A\n",
            "Downloading:  68% 1.18G/1.72G [00:15<00:06, 86.0MB/s]\u001b[A\n",
            "Downloading:  69% 1.18G/1.72G [00:15<00:06, 85.1MB/s]\u001b[A\n",
            "Downloading:  69% 1.19G/1.72G [00:15<00:06, 80.5MB/s]\u001b[A\n",
            "Downloading:  70% 1.20G/1.72G [00:15<00:06, 80.6MB/s]\u001b[A\n",
            "Downloading:  70% 1.21G/1.72G [00:16<00:06, 81.8MB/s]\u001b[A\n",
            "Downloading:  71% 1.22G/1.72G [00:16<00:06, 82.7MB/s]\u001b[A\n",
            "Downloading:  71% 1.23G/1.72G [00:16<00:05, 84.2MB/s]\u001b[A\n",
            "Downloading:  72% 1.23G/1.72G [00:16<00:05, 82.1MB/s]\u001b[A\n",
            "Downloading:  72% 1.24G/1.72G [00:16<00:06, 74.3MB/s]\u001b[A\n",
            "Downloading:  73% 1.25G/1.72G [00:16<00:06, 75.1MB/s]\u001b[A\n",
            "Downloading:  73% 1.26G/1.72G [00:16<00:06, 69.4MB/s]\u001b[A\n",
            "Downloading:  74% 1.27G/1.72G [00:16<00:06, 70.3MB/s]\u001b[A\n",
            "Downloading:  74% 1.28G/1.72G [00:16<00:05, 79.4MB/s]\u001b[A\n",
            "Downloading:  75% 1.29G/1.72G [00:17<00:05, 86.1MB/s]\u001b[A\n",
            "Downloading:  75% 1.29G/1.72G [00:17<00:04, 85.0MB/s]\u001b[A\n",
            "Downloading:  76% 1.30G/1.72G [00:17<00:04, 83.3MB/s]\u001b[A\n",
            "Downloading:  76% 1.31G/1.72G [00:17<00:04, 83.9MB/s]\u001b[A\n",
            "Downloading:  77% 1.32G/1.72G [00:17<00:05, 78.8MB/s]\u001b[A\n",
            "Downloading:  77% 1.33G/1.72G [00:17<00:04, 78.4MB/s]\u001b[A\n",
            "Downloading:  78% 1.34G/1.72G [00:17<00:04, 80.9MB/s]\u001b[A\n",
            "Downloading:  78% 1.35G/1.72G [00:17<00:04, 81.5MB/s]\u001b[A\n",
            "Downloading:  79% 1.35G/1.72G [00:17<00:04, 82.5MB/s]\u001b[A\n",
            "Downloading:  79% 1.36G/1.72G [00:17<00:04, 83.7MB/s]\u001b[A\n",
            "Downloading:  80% 1.37G/1.72G [00:18<00:04, 81.7MB/s]\u001b[A\n",
            "Downloading:  80% 1.38G/1.72G [00:18<00:04, 77.1MB/s]\u001b[A\n",
            "Downloading:  81% 1.39G/1.72G [00:18<00:04, 81.8MB/s]\u001b[A\n",
            "Downloading:  81% 1.40G/1.72G [00:18<00:04, 79.6MB/s]\u001b[A\n",
            "Downloading:  82% 1.40G/1.72G [00:18<00:06, 51.1MB/s]\u001b[A\n",
            "Downloading:  82% 1.42G/1.72G [00:18<00:04, 63.0MB/s]\u001b[A\n",
            "Downloading:  83% 1.43G/1.72G [00:18<00:04, 72.0MB/s]\u001b[A\n",
            "Downloading:  83% 1.43G/1.72G [00:19<00:03, 72.6MB/s]\u001b[A\n",
            "Downloading:  84% 1.44G/1.72G [00:19<00:03, 78.4MB/s]\u001b[A\n",
            "Downloading:  84% 1.45G/1.72G [00:19<00:03, 80.6MB/s]\u001b[A\n",
            "Downloading:  85% 1.46G/1.72G [00:19<00:03, 81.1MB/s]\u001b[A\n",
            "Downloading:  85% 1.47G/1.72G [00:19<00:03, 74.6MB/s]\u001b[A\n",
            "Downloading:  86% 1.48G/1.72G [00:19<00:02, 80.3MB/s]\u001b[A\n",
            "Downloading:  87% 1.49G/1.72G [00:19<00:03, 74.5MB/s]\u001b[A\n",
            "Downloading:  87% 1.50G/1.72G [00:19<00:02, 75.4MB/s]\u001b[A\n",
            "Downloading:  87% 1.50G/1.72G [00:19<00:02, 75.1MB/s]\u001b[A\n",
            "Downloading:  88% 1.51G/1.72G [00:20<00:02, 80.1MB/s]\u001b[A\n",
            "Downloading:  88% 1.52G/1.72G [00:20<00:02, 78.3MB/s]\u001b[A\n",
            "Downloading:  89% 1.53G/1.72G [00:20<00:02, 78.7MB/s]\u001b[A\n",
            "Downloading:  89% 1.54G/1.72G [00:20<00:02, 72.2MB/s]\u001b[A\n",
            "Downloading:  90% 1.54G/1.72G [00:20<00:02, 75.3MB/s]\u001b[A\n",
            "Downloading:  90% 1.55G/1.72G [00:20<00:02, 74.1MB/s]\u001b[A\n",
            "Downloading:  91% 1.56G/1.72G [00:20<00:02, 73.7MB/s]\u001b[A\n",
            "Downloading:  91% 1.57G/1.72G [00:20<00:02, 54.2MB/s]\u001b[A\n",
            "Downloading:  92% 1.58G/1.72G [00:20<00:02, 63.3MB/s]\u001b[A\n",
            "Downloading:  92% 1.58G/1.72G [00:21<00:01, 67.4MB/s]\u001b[A\n",
            "Downloading:  93% 1.59G/1.72G [00:21<00:01, 71.7MB/s]\u001b[A\n",
            "Downloading:  93% 1.60G/1.72G [00:21<00:01, 71.6MB/s]\u001b[A\n",
            "Downloading:  94% 1.61G/1.72G [00:21<00:01, 64.1MB/s]\u001b[A\n",
            "Downloading:  94% 1.62G/1.72G [00:21<00:01, 64.3MB/s]\u001b[A\n",
            "Downloading:  94% 1.62G/1.72G [00:21<00:01, 68.4MB/s]\u001b[A\n",
            "Downloading:  95% 1.63G/1.72G [00:21<00:01, 72.7MB/s]\u001b[A\n",
            "Downloading:  95% 1.64G/1.72G [00:21<00:01, 72.0MB/s]\u001b[A\n",
            "Downloading:  96% 1.65G/1.72G [00:21<00:01, 66.7MB/s]\u001b[A\n",
            "Downloading:  96% 1.65G/1.72G [00:22<00:00, 71.6MB/s]\u001b[A\n",
            "Downloading:  97% 1.66G/1.72G [00:22<00:00, 78.6MB/s]\u001b[A\n",
            "Downloading:  97% 1.67G/1.72G [00:22<00:00, 78.9MB/s]\u001b[A\n",
            "Downloading:  98% 1.68G/1.72G [00:22<00:00, 79.9MB/s]\u001b[A\n",
            "Downloading:  98% 1.69G/1.72G [00:22<00:00, 80.2MB/s]\u001b[A\n",
            "Downloading:  99% 1.70G/1.72G [00:22<00:00, 80.0MB/s]\u001b[A\n",
            "Downloading:  99% 1.71G/1.72G [00:22<00:00, 81.0MB/s]\u001b[A\n",
            "Downloading: 100% 1.72G/1.72G [00:22<00:00, 75.2MB/s]\n",
            "Fetching 15 files:  87% 13/15 [00:37<00:15,  7.52s/it]\n",
            "Downloading: 100% 609/609 [00:00<00:00, 552kB/s]\n",
            "Fetching 15 files:  93% 14/15 [00:37<00:05,  5.40s/it]\n",
            "Downloading:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading:   6% 9.83M/167M [00:00<00:01, 98.3MB/s]\u001b[A\n",
            "Downloading:  12% 20.5M/167M [00:00<00:01, 103MB/s] \u001b[A\n",
            "Downloading:  18% 30.9M/167M [00:00<00:01, 104MB/s]\u001b[A\n",
            "Downloading:  25% 41.3M/167M [00:00<00:01, 103MB/s]\u001b[A\n",
            "Downloading:  31% 51.6M/167M [00:00<00:01, 91.2MB/s]\u001b[A\n",
            "Downloading:  36% 61.0M/167M [00:00<00:01, 91.9MB/s]\u001b[A\n",
            "Downloading:  42% 70.3M/167M [00:00<00:01, 82.8MB/s]\u001b[A\n",
            "Downloading:  47% 78.8M/167M [00:00<00:01, 69.0MB/s]\u001b[A\n",
            "Downloading:  51% 86.2M/167M [00:01<00:01, 68.3MB/s]\u001b[A\n",
            "Downloading:  56% 93.3M/167M [00:01<00:01, 66.8MB/s]\u001b[A\n",
            "Downloading:  60% 100M/167M [00:01<00:01, 63.1MB/s] \u001b[A\n",
            "Downloading:  64% 107M/167M [00:01<00:00, 61.4MB/s]\u001b[A\n",
            "Downloading:  68% 113M/167M [00:01<00:00, 62.0MB/s]\u001b[A\n",
            "Downloading:  71% 119M/167M [00:01<00:00, 61.7MB/s]\u001b[A\n",
            "Downloading:  75% 126M/167M [00:01<00:00, 60.8MB/s]\u001b[A\n",
            "Downloading:  79% 132M/167M [00:01<00:00, 60.3MB/s]\u001b[A\n",
            "Downloading:  82% 138M/167M [00:01<00:00, 60.7MB/s]\u001b[A\n",
            "Downloading:  86% 144M/167M [00:02<00:00, 60.4MB/s]\u001b[A\n",
            "Downloading:  90% 150M/167M [00:02<00:00, 57.9MB/s]\u001b[A\n",
            "Downloading:  94% 157M/167M [00:02<00:00, 60.6MB/s]\u001b[A\n",
            "Downloading: 100% 167M/167M [00:02<00:00, 69.5MB/s]\n",
            "Fetching 15 files: 100% 15/15 [00:40<00:00,  2.69s/it]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "Fetching 15 files: 100% 15/15 [00:00<00:00, 24347.74it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "100% 51/51 [00:17<00:00,  2.87it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "100% 51/51 [00:13<00:00,  3.68it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "100% 51/51 [00:14<00:00,  3.60it/s]\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "Pipelines loaded with `torch_dtype=torch.float16` cannot run with `cpu` or `mps` device. It is not recommended to move them to `cpu` or `mps` as running them will fail. Please make sure to use a `cuda` device to run the pipeline in inference. due to the lack of support for `float16` operations on those devices in PyTorch. Please remove the `torch_dtype=torch.float16` argument, or use a `cuda` device to run inference.\n",
            "100% 38/38 [00:10<00:00,  3.56it/s]\n"
          ]
        }
      ],
      "source": [
        "!python shashaa_ai_img_gen_bot/bot.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "683563d8ccd84ee795a84368e1327525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65a5af07183c49679414297bfab97ac1",
              "IPY_MODEL_0d3f2e59b7d3455fb6ab687edf68894a",
              "IPY_MODEL_c05b54a5a519461680346b97613cf569",
              "IPY_MODEL_0f6d549239884d4790f7504add08aa5d"
            ],
            "layout": "IPY_MODEL_5b939aac19b5469ea5ed3668a92617f0"
          }
        },
        "65a5af07183c49679414297bfab97ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa67d9e650e422e8c504fdd1999508f",
            "placeholder": "​",
            "style": "IPY_MODEL_41ef71803dc249a2b0101121a5a24693",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "0d3f2e59b7d3455fb6ab687edf68894a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bee3ce59c52743cbada04a256d5431a8",
            "placeholder": "​",
            "style": "IPY_MODEL_0588e46ff66147f193f5caec09535bea",
            "value": ""
          }
        },
        "c05b54a5a519461680346b97613cf569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_fbba3347837a4ddb988ac65e2ae2bcac",
            "style": "IPY_MODEL_07bf9e3f7e3d4fe6bdb4c7f5b20bf67f",
            "tooltip": ""
          }
        },
        "0f6d549239884d4790f7504add08aa5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e281cc9bb5d94ef7b66196c06f110f2e",
            "placeholder": "​",
            "style": "IPY_MODEL_ec24325570aa4e7e9a7f40c894a01007",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "5b939aac19b5469ea5ed3668a92617f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "7fa67d9e650e422e8c504fdd1999508f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ef71803dc249a2b0101121a5a24693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bee3ce59c52743cbada04a256d5431a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0588e46ff66147f193f5caec09535bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbba3347837a4ddb988ac65e2ae2bcac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07bf9e3f7e3d4fe6bdb4c7f5b20bf67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e281cc9bb5d94ef7b66196c06f110f2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec24325570aa4e7e9a7f40c894a01007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}